#!/usr/bin/python -Wignore
# Myron Walker , April 2012
"""
This file contains documentation about the GCC compiler and the code coverage file formats that were taken
from the 'filename' that is part of the GCC source.  I re-wrote the documentation some to attempt to clarify
some aspects of the file formats.  The GCC software is copywrited under the following terms.

    GCC is free software; you can redistribute it and/or modify it under
    the terms of the GNU General Public License as published by the Free
    Software Foundation; either version 2, or (at your option) any later
    version.

    File format for coverage information
    Copyright (C) 1996, 1997, 1998, 2000, 2002,
    2003, 2004, 2005 Free Software Foundation, Inc.
    Contributed by Bob Manson <manson@cygnus.com>.
    Completely remangled by Nathan Sidwell <nathan@codesourcery.com>.

    GCC is distributed in the hope that it will be useful, but WITHOUT ANY
    WARRANTY; without even the implied warranty of MERCHANTABILITY or
    FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
    for more details.

    For more information about the GCC license see the file COPYING that is part of the GCC source distribution.

Coverage information is held in two files.  A notes file, which is generated by the compiler, and a data file, 
which is generated by the program under test.  Both files use a similar structure.  GCC does not attempt to make
these files backwards compatible with previous versions, as you only need coverage information when developing a
program.  The files hold version information, so that mismatches can be detected, and they use a format that allows
tools to skip information they do not understand or are not interested in.

Numbers are recorded in the 32 bit unsigned binary form of the endianness of the machine generating the file. 
64 bit numbers are stored as two 32 bit numbers, the low part first.  Strings are padded with 1 to 4 NUL bytes,
to bring the length up to a multiple of 4. The number of 4 bytes is stored, followed by the padded string. 
Zero length and NULL strings are simply stored as a length of zero (they have no trailing NUL or padding).

    uint32:  byte3 byte2 byte1 byte0 | byte0 byte1 byte2 byte3
    uint64:  uint32:low uint32:high
    string: uint32:0 | uint32:length char* char:0 padding
    padding: | char:0 | char:0 char:0 | char:0 char:0 char:0
    item: uint32 | uint64 | string

The basic format of the files is

    file : uint32:magic uint32:version uint32:stamp record*

The magic ident is different for the notes and the data files.  The magic ident is used to determine the endianness
of the file, when reading.  The version is the same for both files and is derived from gcc's version number. The
stamp value is used to synchronize note and data files and to synchronize merging within a data file. It need not 
be an absolute time stamp, merely a ticker that increments fast enough and cycles slow enough to distinguish
different compile/run/compile cycles.

Although the ident and version are formally 32 bit numbers, they are derived from 4 character ASCII strings.  The
version number consists of the single character major version number, a two character minor version number (leading
zero for versions less than 10), and a single character indicating the status of the release. That will be 'e' 
experimental, 'p' prerelease and 'r' for release. Because, by good fortune, these are in alphabetical order, string
collating can be used to compare version strings.  Be aware that the 'e' designation will (naturally) be unstable
and might be incompatible with itself.  For gcc 3.4 experimental, it would be '304e' (0x33303465).  When the major
version reaches 10, the letters A-Z will be used.  Assuming minor increments releases every 6 months, we have to
make a major increment every 50 years. Assuming major increments releases every 5 years, we're ok for the next
155 years -- good enough for me.

   A record has a tag, length and variable amount of data.

       record: header data
    header: uint32:tag uint32:length
    data: item*

Records are not nested, but there is a record hierarchy.  Tag numbers reflect this hierarchy.  Tags are unique
across note and data files.  Some record types have a varying amount of data.  The LENGTH is the number of 4bytes
that follow and is usually used to determine how much data.  The tag value is split into 4 8-bit fields, one for
each of four possible levels.  The most significant is allocated first.  Unused levels are zero.  Active levels are
odd-valued, so that the LSB of the level is one.  A sub-level incorporates the values of its superlevels.  This
formatting allows you to determine the tag hierarchy, without understanding the tags themselves, and is similar
to the standard section numbering used in technical documents.  Level values [1..3f] are used for common tags, 
values [41..9f] for the notes file and [a1..ff] for the data
file.

   The basic block graph file contains the following records
       note: unit function-graph*
          unit: header uint32:checksum string:source
          function-graph: announce_function basic_blocks {arcs | lines}*
              announce_function: header uint32:ident uint32:checksum string:name string:source uint32:lineno
              basic_block: header uint32:flags*
          arcs: header uint32:block_no arc*
              arc:  uint32:dest_block uint32:flags
          lines: header uint32:block_no line*
               uint32:0 string:NULL
              line:  uint32:line_no | uint32:0 string:filename

The BASIC_BLOCK record holds per-bb flags.  The number of blocks can be inferred from its data length.  There is
one ARCS record per basic block.  The number of arcs from a bb is implicit from the data length.  It enumerates the 
destination bb and per-arc flags. There is one LINES record per basic block, it enumerates the source lines which 
belong to that basic block.  Source file names are introduced by a line number of 0, following lines are from the new
source file.  The initial source file for the function is NULL, but the current source file should be remembered from one
LINES record to the next.  The end of a block is indicated by an empty filename - this does not reset the current source
file.  Note there is no ordering of the ARCS and LINES records: they may be in any order, interleaved in any manner.
The current filename follows the order the LINES records are stored in the file, *not* the ordering of the blocks they
are for.

   The data file contains the following records.
        data: {unit function-data* summary:object summary:program*}*
    unit: header uint32:checksum

        function-data:    announce_function arc_counts
    announce_function: header uint32:ident uint32:checksum
    arc_counts: header uint64:count*

    summary: uint32:checksum {count-summary} GCOV_COUNTERS
    count-summary:    uint32:num uint32:runs uint64:sum
            uint64:max uint64:sum_max

The ANNOUNCE_FUNCTION record is the same as that in the note file, but without the source location.  The ARC_COUNTS 
gives the counter values for those arcs that are instrumented.  The SUMMARY records give information about the whole
object file and about the whole program.  The checksum is used for whole program summaries, and disambiguates different
programs which include the same instrumented object file.  There may be several program summaries, each with a unique
checksum.  The object summary's checksum is zero.  Note that the data file might contain information from several runs
concatenated, or the data might be merged.

This file is included by both the compiler, gcov tools and the runtime support library libgcov. IN_LIBGCOV and IN_GCOV
are used to distinguish which case is which.  If IN_LIBGCOV is nonzero, libgcov is being built. If IN_GCOV is nonzero,
the gcov tools are being built. Otherwise the compiler is being built. IN_GCOV may be positive or negative. If positive,
we are compiling a tool that requires additional functions (see the code for knowledge of what those functions are).



Following is a quick description of the tracefile  format  as  used  by genhtml, geninfo and lcov.

       A tracefile is made up of several human-readable lines of text, divided into sections. If available, a tracefile
       begins with the testname which is stored in the following format:

         TN:<test name>

       For each source file referenced in the .da file, there is a section containing filename and coverage data:

         SF:<absolute path to the source file>

       Following is a list of line numbers for each function name found in the source file:

         FN:<line number of function start>,<function name>

       Next, there is a list of execution counts for each instrumented function:

         FNDA:<execution count>,<function name>

       This list is followed by two lines containing the number of functions found and hit:

         FNF:<number of functions found>
         FNH:<number of function hit>

       Branch coverage information is stored which one line per branch:

         BRDA:<line number>,<block number>,<branch number>,<taken>

       Block number and branch number are gcc internal IDs for the branch.  Taken is either '-' if the basic block 
       containing the branch was never executed or a number indicating how often that branch was taken.

       Branch coverage summaries are stored in two lines:

         BRF:<number of branches found>
         BRH:<number of branches hit>

       Then there is a list of execution counts for each instrumented line (i.e. a line which resulted in executable code):

         DA:<line number>,<execution count>[,<checksum>]

       Note that there may be an optional checksum present for each instrumented line.  The current geninfo implementation
       uses an MD5 hash as check summing algorithm.

       At the end of a section, there is a summary about how many lines were found and how many were actually instrumented:

         LH:<number of lines with a non-zero execution count>
         LF:<number of instrumented lines>

       Each sections ends with:

         end_of_record

       In addition to the main source code file there are sections for all #included files which also contain executable code.

       Note that the absolute path of a source file is generated by interpreting  the  contents  of  the  respective .bb file
       (see gcov (1) for more information on this file type). Relative filenames  are  prefixed  with the directory in which the 
       .bb file is found.

       Note  also that symbolic links to the .bb file will be resolved so that the actual file path is used instead of the path
       to a link.  This approach  is  necessary  for  the mechanism to work with the /proc/gcov files.

"""

# Base64 encoded PNGs to use when generating HTML reports code coverage 
class GenHTMLResources:

    AMBER_PNG =   "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAAB3RJTUUH0gcRDygEmMvW4AAAAAlwSFlzAAALEgAACxIB0" + \
                  "t1+/AAAAARnQU1BAACxjwv8YQUAAAAGUExURf/gUAAAAKJ62n4AAAAKSURBVHjaY2AAAAACAAHlJ978AAAAAElFTkSuQmCC"

    EMERALD_PNG = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAAB3RJTUUH0gcRDyIryfUDMwAAAAlwSFlzAAALEgAACxIB0" + \
                  "t1+/AAAAARnQU1BAACxjwv8YQUAAAAGUExURRvqWQoKCg+6UIMAAAAKSURBVHjaY2AAAAACAAHlJ978AAAAAElFTkSuQmCC"

    RUBY_PNG =    "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAAB3RJTUUH0gcRDxgQXVc0bgAAAAlwSFlzAAALEgAACxIB0" + \
                  "t1+/AAAAARnQU1BAACxjwv8YQUAAAAGUExURf81LwAAANAzmp0AAAAKSURBVHjaY2AAAAACAAHlJ978AAAAAElFTkSuQmCC"

    GLASS_PNG =   "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABGdBTUEAALGPC/xhBQAAAAZQTFRF////AAAAVcLTfgAAA" + \
                  "AF0Uk5TAEDm2GYAAAABYktHRACIBR1IAAAACXBIWXMAAAsSAAALEgHS3X78AAAAB3RJTUUH0gcTDwgZxEBWEAAAAApJRE" + \
                  "FUeJxjYAAAAAIAAUivpHEAAAAASUVORK5CYII="

    SNOW_PNG =    "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAAB3RJTUUH0gcRDx4ddbzvVQAAAAlwSFlzAAALEgAACxIB0" + \
                  "t1+/AAAAARnQU1BAACxjwv8YQUAAAAGUExURf///wAAAFXC034AAAAKSURBVHjaY2AAAAACAAHlJ978AAAAAElFTkSuQmCC"

    UPDOWN_PNG =  "iVBORw0KGgoAAAANSUhEUgAAAAoAAAAOCAYAAAAWo42rAAAAPElEQVQoz2NgQAP/oQBdnBFdEYokIyMjhkJspiArZsSnC" + \
                  "FkxIyFFMMDEMGCA+m4kPnhICnBiopCB2EQBAOlcL/XinQ/5AAAAAElFTkSuQmCC"

    GCOV_CSS = """
/* All views: initial background and text color */
body
{
  color: #000000;
  background-color: #FFFFFF;
}

/* All views: standard link format*/
a:link
{
  color: #284FA8;
  text-decoration: underline;
}

/* All views: standard link - visited format */
a:visited
{
  color: #00CB40;
  text-decoration: underline;
}

/* All views: standard link - activated format */
a:active
{
  color: #FF0040;
  text-decoration: underline;
}

/* All views: main title format */
td.title
{
  text-align: center;
  padding-bottom: 10px;
  font-family: sans-serif;
  font-size: 20pt;
  font-style: italic;
  font-weight: bold;
}

/* All views: header item format */
td.headerItem
{
  text-align: right;
  padding-right: 6px;
  font-family: sans-serif;
  font-weight: bold;
  vertical-align: top;
  white-space: nowrap;
}

/* All views: header item value format */
td.headerValue
{
  text-align: left;
  color: #284FA8;
  font-family: sans-serif;
  font-weight: bold;
  white-space: nowrap;
}

/* All views: header item coverage table heading */
td.headerCovTableHead
{
  text-align: center;
  padding-right: 6px;
  padding-left: 6px;
  padding-bottom: 0px;
  font-family: sans-serif;
  font-size: 80%;
  white-space: nowrap;
}

/* All views: header item coverage table entry */
td.headerCovTableEntry
{
  text-align: right;
  color: #284FA8;
  font-family: sans-serif;
  font-weight: bold;
  white-space: nowrap;
  padding-left: 12px;
  padding-right: 4px;
  background-color: #DAE7FE;
}

/* All views: header item coverage table entry for high coverage rate */
td.headerCovTableEntryHi
{
  text-align: right;
  color: #000000;
  font-family: sans-serif;
  font-weight: bold;
  white-space: nowrap;
  padding-left: 12px;
  padding-right: 4px;
  background-color: #A7FC9D;
}

/* All views: header item coverage table entry for medium coverage rate */
td.headerCovTableEntryMed
{
  text-align: right;
  color: #000000;
  font-family: sans-serif;
  font-weight: bold;
  white-space: nowrap;
  padding-left: 12px;
  padding-right: 4px;
  background-color: #FFEA20;
}

/* All views: header item coverage table entry for ow coverage rate */
td.headerCovTableEntryLo
{
  text-align: right;
  color: #000000;
  font-family: sans-serif;
  font-weight: bold;
  white-space: nowrap;
  padding-left: 12px;
  padding-right: 4px;
  background-color: #FF0000;
}

/* All views: header legend value for legend entry */
td.headerValueLeg
{
  text-align: left;
  color: #000000;
  font-family: sans-serif;
  font-size: 80%;
  white-space: nowrap;
  padding-top: 4px;
}

/* All views: color of horizontal ruler */
td.ruler
{
  background-color: #6688D4;
}

/* All views: version string format */
td.versionInfo
{
  text-align: center;
  padding-top: 2px;
  font-family: sans-serif;
  font-style: italic;
}

/* Directory view/File view (all)/Test case descriptions:
   table headline format */
td.tableHead
{
  text-align: center;
  color: #FFFFFF;
  background-color: #6688D4;
  font-family: sans-serif;
  font-size: 120%;
  font-weight: bold;
  white-space: nowrap;
  padding-left: 4px;
  padding-right: 4px;
}

span.tableHeadSort
{
  padding-right: 4px;
}

/* Directory view/File view (all): filename entry format */
td.coverFile
{
  text-align: left;
  padding-left: 10px;
  padding-right: 20px; 
  color: #284FA8;
  background-color: #DAE7FE;
  font-family: monospace;
}

/* Directory view/File view (all): bar-graph entry format*/
td.coverBar
{
  padding-left: 10px;
  padding-right: 10px;
  background-color: #DAE7FE;
}

/* Directory view/File view (all): bar-graph outline color */
td.coverBarOutline
{
  background-color: #000000;
}

/* Directory view/File view (all): percentage entry for files with
   high coverage rate */
td.coverPerHi
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px;
  background-color: #A7FC9D;
  font-weight: bold;
  font-family: sans-serif;
}

/* Directory view/File view (all): line count entry for files with
   high coverage rate */
td.coverNumHi
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px;
  background-color: #A7FC9D;
  white-space: nowrap;
  font-family: sans-serif;
}

/* Directory view/File view (all): percentage entry for files with
   medium coverage rate */
td.coverPerMed
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px;
  background-color: #FFEA20;
  font-weight: bold;
  font-family: sans-serif;
}

/* Directory view/File view (all): line count entry for files with
   medium coverage rate */
td.coverNumMed
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px;
  background-color: #FFEA20;
  white-space: nowrap;
  font-family: sans-serif;
}

/* Directory view/File view (all): percentage entry for files with
   low coverage rate */
td.coverPerLo
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px;
  background-color: #FF0000;
  font-weight: bold;
  font-family: sans-serif;
}

/* Directory view/File view (all): line count entry for files with
   low coverage rate */
td.coverNumLo
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px;
  background-color: #FF0000;
  white-space: nowrap;
  font-family: sans-serif;
}

/* File view (all): "show/hide details" link format */
a.detail:link
{
  color: #B8D0FF;
  font-size:80%;
}

/* File view (all): "show/hide details" link - visited format */
a.detail:visited
{
  color: #B8D0FF;
  font-size:80%;
}

/* File view (all): "show/hide details" link - activated format */
a.detail:active
{
  color: #FFFFFF;
  font-size:80%;
}

/* File view (detail): test name entry */
td.test_name
{
  text-align: right;
  padding-right: 10px;
  background-color: #DAE7FE;
  font-family: sans-serif;
}

/* File view (detail): test percentage entry */
td.testPer
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px; 
  background-color: #DAE7FE;
  font-family: sans-serif;
}

/* File view (detail): test lines count entry */
td.testNum
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px; 
  background-color: #DAE7FE;
  font-family: sans-serif;
}

/* Test case descriptions: test name format*/
dt
{
  font-family: sans-serif;
  font-weight: bold;
}

/* Test case descriptions: description table body */
td.testDescription
{
  padding-top: 10px;
  padding-left: 30px;
  padding-bottom: 10px;
  padding-right: 30px;
  background-color: #DAE7FE;
}

/* Source code view: function entry */
td.coverFn
{
  text-align: left;
  padding-left: 10px;
  padding-right: 20px; 
  color: #284FA8;
  background-color: #DAE7FE;
  font-family: monospace;
}

/* Source code view: function entry zero count*/
td.coverFnLo
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px;
  background-color: #FF0000;
  font-weight: bold;
  font-family: sans-serif;
}

/* Source code view: function entry nonzero count*/
td.coverFnHi
{
  text-align: right;
  padding-left: 10px;
  padding-right: 10px;
  background-color: #DAE7FE;
  font-weight: bold;
  font-family: sans-serif;
}

/* Source code view: source code format */
pre.source
{
  font-family: monospace;
  white-space: pre;
  margin-top: 2px;
}

/* Source code view: line number format */
span.lineNum
{
  background-color: #EFE383;
}

/* Source code view: format for lines which were executed */
td.lineCov,
span.lineCov
{
  background-color: #CAD7FE;
}

/* Source code view: format for Cov legend */
span.coverLegendCov
{
  padding-left: 10px;
  padding-right: 10px;
  padding-bottom: 2px;
  background-color: #CAD7FE;
}

/* Source code view: format for lines which were not executed */
td.line_noCov,
span.line_noCov
{
  background-color: #FF6230;
}

/* Source code view: format for NoCov legend */
span.coverLegendNoCov
{
  padding-left: 10px;
  padding-right: 10px;
  padding-bottom: 2px;
  background-color: #FF6230;
}

/* Source code view (function table): standard link - visited format */
td.line_noCov > a:visited,
td.lineCov > a:visited
{  
  color: black;
  text-decoration: underline;
}  

/* Source code view: format for lines which were executed only in a
   previous version */
span.lineDiffCov
{
  background-color: #B5F7AF;
}

/* Source code view: format for branches which were executed
 * and taken */
span.branchCov
{
  background-color: #CAD7FE;
}

/* Source code view: format for branches which were executed
 * but not taken */
span.branchNoCov
{
  background-color: #FF6230;
}

/* Source code view: format for branches which were not executed */
span.branchNoExec
{
  background-color: #FF6230;
}

/* Source code view: format for the source code heading line */
pre.sourceHeading
{
  white-space: pre;
  font-family: monospace;
  font-weight: bold;
  margin: 0px;
}

/* All views: header legend value for low rate */
td.headerValueLegL
{
  font-family: sans-serif;
  text-align: center;
  white-space: nowrap;
  padding-left: 4px;
  padding-right: 2px;
  background-color: #FF0000;
  font-size: 80%;
}

/* All views: header legend value for med rate */
td.headerValueLegM
{
  font-family: sans-serif;
  text-align: center;
  white-space: nowrap;
  padding-left: 2px;
  padding-right: 2px;
  background-color: #FFEA20;
  font-size: 80%;
}

/* All views: header legend value for hi rate */
td.headerValueLegH
{
  font-family: sans-serif;
  text-align: center;
  white-space: nowrap;
  padding-left: 2px;
  padding-right: 4px;
  background-color: #A7FC9D;
  font-size: 80%;
}

/* All views except source code view: legend format for low coverage */
span.coverLegendCovLo
{
  padding-left: 10px;
  padding-right: 10px;
  padding-top: 2px;
  background-color: #FF0000;
}

/* All views except source code view: legend format for med coverage */
span.coverLegendCovMed
{
  padding-left: 10px;
  padding-right: 10px;
  padding-top: 2px;
  background-color: #FFEA20;
}

/* All views except source code view: legend format for hi coverage */
span.coverLegendCovHi
{
  padding-left: 10px;
  padding-right: 10px;
  padding-top: 2px;
  background-color: #A7FC9D;
}
"""

    @staticmethod
    def WriteCSS(folder, filename="gcov.css"):

        cssfile = open(filename, 'w')
        cssfile.write(GenHTMLResources.GCOV_CSS)
        cssfile.close()

        return

    @staticmethod
    def WritePNG(folder, filename, base64Buffer):

        pngfile = open(filename, 'w')
        pngbuffer = base64.b64decode(base64Buffer)
        pngfile.write(pngbuffer)
        pngfile.close()

        return

    @staticmethod
    def WritePNG_Amber(folder, filename="amber.png"):
        GenHTMLResources.WritePNG(folder, filename, GenHTMLResources.AMBER_PNG)
        return

    @staticmethod
    def WritePNG_Emerald(folder, filename="emerald.png"):
        GenHTMLResources.WritePNG(folder, filename, GenHTMLResources.EMERALD_PNG)
        return

    @staticmethod
    def WritePNG_Ruby(folder, filename="ruby.png"):
        GenHTMLResources.WritePNG(folder, filename, GenHTMLResources.RUBY_PNG)
        return

    @staticmethod
    def WritePNG_Glass(folder, filename="glass.png"):
        GenHTMLResources.WritePNG(folder, filename, GenHTMLResources.GLASS_PNG)
        return

    @staticmethod
    def WritePNG_Snow(folder, filename="snow.png"):
        GenHTMLResources.WritePNG(folder, filename, GenHTMLResources.SNOW_PNG)
        return

    @staticmethod
    def WritePNG_UpDown(folder, filename="updown.png"):
        GenHTMLResources.WritePNG(folder, filename, GenHTMLResources.UPDOWN_PNG)
        return


import base64
import operator
import os
import sys
import struct

from optparse import OptionGroup, OptionParser 
from optparse import OptParseError, BadOptionError, OptionError, OptionConflictError, OptionValueError

VERBOSE = True

def vprint(content=""):
    if VERBOSE:
        print(content)

class GCovInfoBranch:
    def __init__(self, lineno, blockno, branchno, taken=None):
        self.line_number = lineno
        self.block_number = blockno
        self.branch_number = branchno
        self.taken_counter = taken

    def IncrementTakenCount(self, incVal):
        if self.taken_counter is None:
            self.taken_counter = incVal
        else:
            self.taken_counter = self.taken_counter + incVal
        return

class GCovInfoFunction:
    def __init__(self, funcname, lineno, executionCount=0):
        self.function_name = funcname
        self.line_number = lineno
        self.execution_count = executionCount

    def IncrementExecutionCount(self, incVal):
        self.execution_count = self.execution_count + incVal
        return

class GCovInfoLine:
    def __init__(self, lineno, executionCount=0, checkSum=None):
        self.line_number = lineno
        self.execution_count = executionCount
        self.check_sum = checkSum

    def IncrementExecutionCount(self, incVal):
        self.execution_count = self.execution_count + incVal
        return

    def SetCheckSum(self, checkSum):
        self.check_sum = checkSum

class GCovInfoSourcefileWriter:
    def __init__(self, sourcefile, testname=None):
        self.test_name = ""
        self.sourcefile = sourcefile
        self.branch_traces = []
        self.function_traces = []
        self.line_traces = []

        if testname is not None:
            self.test_name = testname

        return

    def AddBranchTrace(self, lineno, blockno, branchno, taken=None):
        branchTrace = GCovInfoBranch(lineno, blockno, branchno, taken)
        self.branch_traces.append(branchTrace)
        return branchTrace

    def AddFunctionTrace(self, funcname, lineno, executionCount=0):
        funcTrace = GCovInfoFunction(funcname, lineno, executionCount)
        self.function_traces.append(funcTrace)

        return funcTrace

    def AddLineTrace(self, lineno, executionCount=0, checkSum=None):
        lineTrace = GCovInfoLine(lineno, executionCount, checkSum)
        self.line_traces.append(lineTrace)
        return lineTrace

    def WriteTo(self, fileHandle):
        """
        """
        # --------------------------------------------------
        # Write out the Sourcefile name
        # --------------------------------------------------
        sourcefile = self.sourcefile
        fileHandle.write("SF:%s\n" % sourcefile)

        # --------------------------------------------------
        # Write out the Function traces
        # --------------------------------------------------
        functionsCount = len(self.function_traces)
        functionsHit = 0

        for ftrace in self.function_traces:
            fileHandle.write("FN:%d,%s\n" % (ftrace.line_number, ftrace.function_name))

        for ftrace in self.function_traces:
            if (ftrace.execution_count > 0):
                functionsHit = functionsHit + 1
            fileHandle.write("FNDA:%d,%s\n" % (ftrace.execution_count, ftrace.function_name))

        fileHandle.write("FNF:%d\n" % functionsCount)
        fileHandle.write("FNH:%d\n" % functionsHit)

        # --------------------------------------------------
        # Write out the Branch traces
        # --------------------------------------------------
        branchesCount = len(self.branch_traces)
        branchesHit = 0

        if branchesCount > 0:
            for btrace in self.branch_traces:
                if (btrace.taken_counter is not None):
                    branchesHit = branchesHit + 1
                    fileHandle.write("BRDA:%d,%d,%d,%d\n" % (btrace.line_number, btrace.block_number, btrace.branch_number, btrace.taken_counter))
                else:
                    fileHandle.write("BRDA:%d,%d,%d,-\n" % (btrace.line_number, btrace.block_number, btrace.branch_number))

            fileHandle.write("BRF:%d\n" % branchesCount)
            fileHandle.write("BRH:%d\n" % branchesHit)

        # --------------------------------------------------
        # Write out the Line traces
        # --------------------------------------------------
        linesCount = len(self.line_traces)
        linesHit = 0

        if linesCount > 0:
            for ltrace in self.line_traces:
                if ltrace.execution_count > 0:
                    linesHit = linesHit + 1
                if ltrace.check_sum is not None:
                    fileHandle.write("DA:%d,%d,%d\n" % (ltrace.line_number, ltrace.execution_count, ltrace.check_sum))
                else:
                    fileHandle.write("DA:%d,%d\n" % (ltrace.line_number, ltrace.execution_count))

            fileHandle.write("LF:%d\n" % linesCount)
            fileHandle.write("LH:%d\n" % linesHit)

        # --------------------------------------------------
        # Write out the end of record marker
        # --------------------------------------------------
        fileHandle.write("end_of_record\n")

        return

class GCovInfoFileWriter:
    def __init__(self, traceFile, testname=None):
        """
            Valid 'testname' values consist of letters, numerical digits, and the underscore character.
        """
        self.test_name = ""
        self.trace_file = traceFile

        if testname is not None:
            self.test_name = testname

        return

    @staticmethod
    def GetSortedKeys(coverageMapItem):
        sortedKeys = []

        keyLookupDictionary = {}

        funcGraphs = coverageMapItem.function_graphs

        for fgraph in funcGraphs.values():
            origSrc = fgraph.orig_source
            fullSrc = fgraph.source

            keyLookupDictionary[origSrc] = fullSrc

        keyList = [k for k in keyLookupDictionary.keys()]
        keyList.sort()

        for okey in keyList:
            fkey = keyLookupDictionary[okey]
            sortedKeys.append(fkey)

        return sortedKeys

    TraceList = ["_sigbits",
                 "_sputc", 
                 "graph_loop_for",
                 "graph_nestedbranch_simple"]

    @staticmethod
    def TraceGraph(funcGraph, dumpinfo=False):

        funcName = funcGraph.name

        if (GCovInfoFileWriter.TraceList is not None) and operator.contains(GCovInfoFileWriter.TraceList, funcName):
            dumpinfo = True

        if dumpinfo is not None:
            if dumpinfo:
                vprint ("")
                vprint ("Function (%s : %d): Solved=%s" % (funcGraph.name, funcGraph.indent, funcGraph.solved))
                vprint ("+--------------------------------------------------------------------------------------------------------+")
                vprint ("")

                lastBlockIndex = len(funcGraph.blocks)
                blockIndex = 0

                while blockIndex < lastBlockIndex:
                    block = funcGraph.blocks[blockIndex]

                    vprint ("    Block (%d): LineNo=%s Flags=%s IsBranchLanding=%s IsCallSite=%s IsExceptionLanding=%s IsReturnLanding=%s HasRelevantBranches=%s" % \
                        (blockIndex, block.line_no, block.flags, block.is_branch_landing, block.is_call_site, block.is_exception_landing, block.is_return_landing, block.has_relevant_branches))

                    vprint ("        PRED ARCS:")

                    collectionLen = len(block.arcs_Predecessors)
                    cindex = 0

                    if collectionLen > 0:
                        while cindex < collectionLen:
                            arc = block.arcs_Predecessors[cindex]
                            vprint ("            (%d) - DestBlockNo=%d Fake=%s FallThru=%s OnTree=%s IsRelevantBranch=%s IsExceptionBranch=%s" % \
                                    (cindex, arc.dest_block, arc.has_flag_fake, arc.has_flag_fall_through, arc.has_flag_on_tree, arc.is_relevant_branch, arc.is_exception_branch))
                            cindex += 1
                    else:
                        vprint ("            (EMPTY)")

                    vprint ("        SUCC ARCS:")

                    collectionLen = len(block.arcs_successors)
                    cindex = 0

                    if collectionLen > 0:
                        while cindex < collectionLen:
                            arc = block.arcs_successors[cindex]
                            vprint ("            (%d) - DestBlockNo=%d Fake=%s FallThru=%s OnTree=%s IsRelevantBranch=%s IsReturnBranch=%s IsExceptionBranch=%s" % \
                                    (cindex, arc.dest_block, arc.has_flag_fake, arc.has_flag_fall_through, arc.has_flag_on_tree, arc.is_relevant_branch, arc.is_return_branch, arc.is_exception_branch))
                            cindex += 1
                    else:
                        vprint ("            (EMPTY)")

                    vprint ("        LINES:")

                    collectionLen = 0
                    if block.lines is not None:
                        collectionLen = len(block.lines)
                    else:
                        vprint ("            (EMPTY)")

                    cindex = 0

                    while(cindex < collectionLen):
                        line = block.lines[cindex]
                        vprint ("            (%d) - %s" % (line.number, line.content))
                        cindex += 1

                    vprint("")

                    blockIndex += 1
                    #end while(blockIndex < lastBlockIndex)

                blockIndex = 0

                vprint ("|  BLOCK  |  ARC  |  COUNTER  |")

                while blockIndex < lastBlockIndex:
                    block = funcGraph.blocks[blockIndex]

                    collectionLen = len(block.arcs_successors)
                    cindex = 0

                    if collectionLen > 0:
                        while cindex < collectionLen:
                            arc = block.arcs_successors[cindex]
                            arcIndexStr = ("%d" % cindex).center(7)
                            if arc.counter is None:
                                arcCounterStr = "     -     "
                            else:
                                arcCounterStr = ("%d" % arc.counter).center(11)
                            if cindex == 0:
                                blkIndexStr = ("%d" % blockIndex).center(9)
                            else:
                                blkIndexStr = "         "
                            vprint ("|%s|%s|%s|" % (blkIndexStr, arcIndexStr, arcCounterStr))
                            cindex += 1

                    blockIndex += 1
                    #end while(blockIndex < lastBlockIndex)

                vprint ("")
                vprint ("+--------------------------------------------------------------------------------------------------------+")
                vprint ("")
                vprint ("")
            #end if dumpinfo:
            else:
                vprint ("Function (%s : %d): Solved=%s" % (funcGraph.name, funcGraph.indent, funcGraph.solved))

        return

    def WriteSourcefileSection(self, coverageMapItem, testname=None):
        """
            Takes a coverage map item and writes a source file section to the output tracefile. 
        """

        sectionTestname = self.test_name
        if testname is not None:
            sectionTestname = testname

        sourcesMap = coverageMapItem.sources_map

        sourcesMapKeys = GCovInfoFileWriter.GetSortedKeys(coverageMapItem)

        writableFileCount = 0
        for sourcefile in sourcesMapKeys:
            if os.path.isabs(sourcefile):
                writableFileCount += 1

        if writableFileCount > 0:
            # --------------------------------------------------
            # Write out the Testcase name
            # --------------------------------------------------
            self.trace_file.write("TN:%s\n" % self.test_name)

            for sourcefile in sourcesMapKeys:
                if not os.path.isabs(sourcefile):
                    continue

                sourceGraphs = sourcesMap[sourcefile]

                sourcefileWriter = GCovInfoSourcefileWriter(sourcefile, sectionTestname)

                for funcGraph in sourceGraphs.values():

                    if funcGraph.solved:
                        GCovInfoFileWriter.TraceGraph(funcGraph)

                        sourcefileWriter.AddFunctionTrace(funcGraph.name, funcGraph.line_no, funcGraph.execution_count)

                        blockWithLinesCounter = 0

                        lastBlockIndex = len(funcGraph.blocks)
                        blockIndex = 0
                        relevantBlockIndex = 0
                        relevantBranchIndex = 0

                        branchLineNo = None

                        while blockIndex < lastBlockIndex:
                            block = funcGraph.blocks[blockIndex]

                            hasLines = False
                            if (block.lines is not None) and (len(block.lines) > 0):
                                hasLines = True

                            blockExecCount = 0
                            for arc in block.arcs_successors:
                                taken = arc.counter
                                blockExecCount += taken

                            if hasLines:
                                for line in block.lines:
                                    lineNumber = line.number
                                    if lineNumber > 0:
                                        branchLineNo = lineNumber
                                        checksum = None
                                        sourcefileWriter.AddLineTrace(line.number, blockExecCount, checksum)

                                relevantBlockIndex = 0
                                relevantBranchIndex = 0

                            if block.has_relevant_branches:
                                if block.is_call_site:
                                    for arc in block.arcs_successors:
                                        if not arc.has_flag_fake:
                                            relevantBranchIndex += 1
                                else:
                                    for arc in block.arcs_successors:
                                        takenCounter = arc.counter
                                        if blockExecCount > 0:
                                            sourcefileWriter.AddBranchTrace(branchLineNo, relevantBlockIndex, relevantBranchIndex, takenCounter)
                                        else:
                                            sourcefileWriter.AddBranchTrace(branchLineNo, relevantBlockIndex, relevantBranchIndex, None)

                                        relevantBranchIndex += 1
                                    relevantBlockIndex += 1
                            else:
                                if block.is_loop:
                                    loopToBlockNo = None
                                    for arc in block.arcs_successors:
                                        if arc.dest_block < blockIndex:
                                            loopToBlockNo = arc.dest_block - 1
                                            break

                                    if loopToBlockNo is not None:
                                        loopToBlock = funcGraph.blocks[loopToBlockNo]
                                        for line in loopToBlock.lines:
                                            branchLineNo = line.number
                                        for arc in block.arcs_successors:
                                            takenCounter = arc.counter
                                            if blockExecCount > 0:
                                                sourcefileWriter.AddBranchTrace(branchLineNo, relevantBlockIndex, relevantBranchIndex, takenCounter)
                                            else:
                                                sourcefileWriter.AddBranchTrace(branchLineNo, relevantBlockIndex, relevantBranchIndex, None)

                                            relevantBranchIndex += 1
                                        relevantBlockIndex += 1

                            blockIndex += 1
                            #end while(blockIndex < lastBlockIndex)
                    else:
                        GCovInfoFileWriter.TraceGraph(funcGraph, True)

                sourcefileWriter.WriteTo(self.trace_file)

        return

GCOVIO_STRINGPADDING = ['\x00\x00\x00\x00', '\x00\x00\x00', '\x00\x00', '\x00']

class GCovIOConst:

    GCOV_VERSION_3_4_0    = 0x30400
    GCOV_VERSION_3_3_0    = 0x30300

    BBG_FILE_MAGIC    = 0x67626267    #gbbg
    GCNO_FILE_MAGIC   = 0x67636e6f    #gcno
    GCDA_FILE_MAGIC   = 0x67636461    #gcda

    GCNO_FILE_MAGIC_BIGENDIAN   = 0x6f6e6367    #oncg
    GCDA_FILE_MAGIC_BIGENDIAN   = 0x61646367    #adcg

    GCOV_TAG_FUNCTION         = 0x01000000
    GCOV_TAG_BLOCKS           = 0x01410000
    GCOV_TAG_ARCS             = 0x01430000
    GCOV_TAG_LINES            = 0x01450000
    GCOV_TAG_COUNTER_BASE     = 0x01a10000
    GCOV_TAG_OBJECT_SUMMARY   = 0xa1000000 # Obsolete
    GCOV_TAG_PROGRAM_SUMMARY  = 0xa3000000

    #GCNO_SOURCEFILE = 0x80000001
    #GCNO_FUNCTIONNAME = 0x80000002

    GCOVIO_TAGTYPE_STR = { GCOV_TAG_FUNCTION: "GCOV_TAG_FUNCTION", 
                           GCOV_TAG_BLOCKS: "GCOV_TAG_BLOCKS", 
                           GCOV_TAG_ARCS: "GCOV_TAG_ARCS", 
                           GCOV_TAG_LINES: "GCOV_TAG_LINES", 
                           GCOV_TAG_COUNTER_BASE: "GCOV_TAG_COUNTER_BASE", 
                           GCOV_TAG_OBJECT_SUMMARY: "GCOV_TAG_OBJECT_SUMMARY", 
                           GCOV_TAG_PROGRAM_SUMMARY: "GCOV_TAG_PROGRAM_SUMMARY" }

    PACKUINT32="=I"
    PACKUINT32_BIGENDIAN="=I"

    LOWORDERMASK =  0x00000000ffffffff
    HIGHORDERMASK = 0xffffffff00000000

    GCOV_FLAG_ARC_ON_TREE = 1
    GCOV_FLAG_ARC_FAKE = 2
    GCOV_FLAG_ARC_FALLTHROUGH = 4

class GCovIOFileHeader():
    """
        uint32:magic 
        uint32:version 
        uint32:stamp
    """
    def __init__(self, magic, version, stamp):
        self.magic = magic
        self.version = version
        self.stamp = stamp
        return

class GCovIORecordHeader():
    """
        uint32:tag uint32:length
    """
    def __init__(self, tag, length):
        self.tag = tag
        self.length = length
        return

class GCovIORecord():
    """
        A gcov record consists of a header followed by a data buffer.  The head contains a 
        tag and length member.  The tag indicates the type of record and the length indicates
        the size of the buffer in 4 byte words.

             Record => [Header] [Buffer]

             Header => [UInt32: Tag] [UInt32: Length]

             Buffer => [Items]*

        The buffer in a gcov record is composed of items.  The items are grouped in various ways
        they are of three basic types.

             UInt32 (stored in the endieness of the host machine)
             UInt64 => [UInt32 (low)] [UInt32 (high)]
             String => [Length] [CharBuffer]

        Strings for a gcov record are padded using from 1 to 4 bytes of padding to ensure the 
        string length ends on a 32bit word boundry.  A null string is represented as a string with
        a length of 0 and no buffer and therefore no padding.

            NullString => [Length: 0]
    """
    def __init__(self, tag, length, itemsData):
        self.header = GCovIORecordHeader(tag, length)
        self.items_data=itemsData
        return

    def __str__(self):
        tagKey = self.header.tag
        tagType = str(tagKey)
        if tagKey in GCovIOConst.GCOVIO_TAGTYPE_STR:
            tagType = GCovIOConst.GCOVIO_TAGTYPE_STR[tagKey]
        strval = "Type=%s Length=%d" % (tagType, self.header.length)
        return strval

class GCovIO():
    """
        FILE FORMAT:

        == Header ==
        [Magic] + [Version] + [Stamp] + [Records*]

        == Records ==
        [RecordHeader] + [RecordData]

        == RecordHeader ==
        [Tag(UInt32)] + [Length(UInt32)]

        Note: Length is the number of 4 byte words that are stored in the record

        == RecordData ==
        [Items*]

        == Items ==
            [UInt32] | [Int64] | [String]

        UInt32: byte3 byte2 byte1 byte0 | byte0 byte1 byte2 byte3
        UInt64: low (UInt32) high (UInt32)
        String: UInt32:0 | UInt32:length + char* char:0 padding

        Padding: '' | 'x00' | 'x00x00' | 'x00x00x00'
    """
    def __init__(self, filename=None, header=None, records=None):
        self.pack_str32 = GCovIOConst.PACKUINT32

        self.filename = filename
        self.header = header
        self.records = records
        return

    def Load(self, filename=None, detectEndianess=True):
        if filename is not None:
            self.filename = filename

        if self.filename is None:
            raise IOError("GCovIO: Load 'Filename' not set")

        fileHandle = None

        try:
            fileHandle = open(self.filename, 'rb')

            fileSize = os.fstat(fileHandle.fileno()).st_size

            self._LoadFileHeader(fileHandle, fileSize, detectEndianess)
            self._LoadRecords(fileHandle, fileSize)
        finally:
            if fileHandle is not None:
                fileHandle.close()
        return

    def Save(self, filename=None):
        if filename is not None:
            self.filename = filename

        if self.filename is None:
            raise IOError("GCovIO: Save 'Filename' not set")

        try:
            fileHandle = open(self.filename, 'w')

            self._SaveHeader(fileHandle)
            self._SaveRecords(fileHandle)
        finally:
            if fileHandle is not None:
                fileHandle.close()

        return

    def _LoadFileHeader(self, fileHandle, fileSize, detectEndianess):

        magic = GCovIO.ReadUInt32(fileHandle)

        if detectEndianess:
            if (magic == GCovIOConst.GCDA_FILE_MAGIC_BIGENDIAN) or \
               (magic == GCovIOConst.GCNO_FILE_MAGIC_BIGENDIAN):
                self.pack_str32 = GCovIOConst.PACKUINT32_BIGENDIAN

        version = GCovIO.ReadUInt32(fileHandle)
        stamp = GCovIO.ReadUInt32(fileHandle)

        self.header = GCovIOFileHeader(magic, version, stamp)

        return

    def _LoadRecords(self, fileHandle, fileSize):

        self.records = []

        curPos = fileHandle.tell()

        while (curPos < fileSize):

            bytesRemaining = fileSize - curPos
            if bytesRemaining < 8:
                vprint ("Reached the end of file without enough bytes remaining to read a complete record.")
                vprint ("filename=%s" % self.filename)
                vprint ("bytesRemaining=%d" % bytesRemaining)

                extraBuffer = fileHandle.read(bytesRemaining)
                extraBytes = ""

                for byte in extraBuffer:
                    extraBytes += "0x%x " % byte

                vprint ("extraBytes=%s" % extraBytes)

                break

            nxtRecord = GCovIO.ReadRecord(fileHandle)

            if nxtRecord is None:
                break

            self.records.append(nxtRecord)

            curPos = fileHandle.tell()

        return

    def _SaveHeader(self, fileHandle):

        magic = self.header.magic
        version = self.header.version
        stamp = self.header.stamp

        GCovIO.WriteUInt32(fileHandle, magic)
        GCovIO.WriteUInt32(fileHandle, version)
        GCovIO.WriteUInt32(fileHandle, stamp)

        return

    def _SaveRecords(self, fileHandle):

        for record in self.records:
            GCovIO.WriteRecord(fileHandle, record)

        return

    @staticmethod
    def ReadUInt32(fileHandle, packStr=GCovIOConst.PACKUINT32):
        """
            uint32:  byte3 byte2 byte1 byte0 | byte0 byte1 byte2 byte3
        """
        quadByte = fileHandle.read(4)
        if len(quadByte) < 4:
            vprint ("ERROR: Problem reading UInt32, not enough bytes left in record. quadByte=%s" % quadByte)

        val, = struct.unpack(packStr, quadByte)
        return val

    @staticmethod
    def ReadUInt64(fileHandle, packStr=GCovIOConst.PACKUINT32):
        """
            uint64:  uint32:low uint32:high
        """
        lowOrder = GCovIO.ReadUInt32(fileHandle, packStr)
        highOrder = GCovIO.ReadUInt32(fileHandle, packStr)

        val = (highOrder << 32) | lowOrder

        return val

    @staticmethod
    def ReadString(fileHandle, packStr=GCovIOConst.PACKUINT32):
        """
            string: uint32:0 | uint32:length char* char:0 padding
            padding: | char:0 | char:0 char:0 | char:0 char:0 char:0
        """

        wordLength = GCovIO.ReadUInt32(fileHandle, packStr)
        strLen = wordLength * 4

        strVal = fileHandle.read(strLen)

        return strVal

    @staticmethod
    def ReadRecord(fileHandle, packStr=GCovIOConst.PACKUINT32):
        """
            record: header data
            header: uint32:tag uint32:length
              data: item*
        """
        recordTag = GCovIO.ReadUInt32(fileHandle, packStr)
        recordLength = GCovIO.ReadUInt32(fileHandle, packStr)

        byteLen = recordLength * 4
        recordItemsData = fileHandle.read(byteLen)

        return GCovIORecord(recordTag, recordLength, recordItemsData)

    @staticmethod
    def UnpackUInt32(buffer, pos, packStr=GCovIOConst.PACKUINT32):

        #Note: The comma is important because the return type from struct.unpack_from is a tuple
        val, = struct.unpack_from(packStr, buffer, pos)
        cpos = pos + 4
        return val, cpos

    @staticmethod
    def UnpackUInt64(buffer, pos, packStr=GCovIOConst.PACKUINT32):

        cpos = pos

        #Note: The comma is important because the return type from struct.unpack_from is a tuple
        lowOrder, = struct.unpack_from(packStr, buffer, cpos)
        cpos = cpos + 4

        highOrder, = struct.unpack_from(packStr, buffer, cpos)
        cpos = cpos + 4

        val = (highOrder << 32) | lowOrder

        return val, cpos

    @staticmethod
    def UnpackString(buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
        """
        #Note: The comma is important because the return type from struct.unpack_from is a tuple
        strWords, = struct.unpack_from(packStr, buffer, pos)
        cpos = pos + 4

        val = None

        if strWords > 0:
            strlen = strWords * 4
            strend = cpos + strlen

            buffSlice = buffer[cpos: strend]
            val = buffSlice.rstrip(b'\x00').decode()

            cpos = cpos + strlen

        return val, cpos

    @staticmethod
    def WriteUInt32(fileHandle, val, packStr=GCovIOConst.PACKUINT32):
        """
            uint32:  byte3 byte2 byte1 byte0 | byte0 byte1 byte2 byte3
        """
        fileHandle.write(struct.pack(packStr, val))
        return

    @staticmethod
    def WriteUInt64(fileHandle, val, packStr=GCovIOConst.PACKUINT32):
        """
            uint64:  uint32:low uint32:high
        """
        lowOrder = val &  GCovIOConst.LOWORDERMASK
        highOrder = (val & GCovIOConst.HIGHORDERMASK) >> 32

        # Write the low order word
        GCovIO.WriteUInt32(fileHandle, lowOrder)

        # Write the high order word
        GCovIO.WriteUInt32(fileHandle, highOrder)

        return

    @staticmethod
    def WriteString(fileHandle, val):
        """
            string: uint32:0 | uint32:length char* char:0 padding
            padding: | char:0 | char:0 char:0 | char:0 char:0 char:0
        """
        valLen = len(val)
        padlen = valLen % 4

        fileHandle.write(val)

        if (val[valLen - 1] == 'x00') and (padlen == 0):
            return

        fileHandle.write(GCOVIO_STRINGPADDING[padlen])

        return

    @staticmethod
    def WriteRecord(fileHandle, record):
        """
            record: header data
            header: uint32:tag uint32:length
              data: item*
        """
        recordTag = record.tag
        GCovIO.WriteUInt32(fileHandle, recordTag)

        recordLength = record.length
        GCovIO.WriteUInt32(fileHandle, recordLength)

        recordItemsData = record.items_data
        GCovIO.WriteUInt32(fileHandle, recordItemsData)

        return

class GCovCoverageMapItem:
    def __init__(self, dataLeaf, funcGraphs):
        self.data_leaf = dataLeaf
        self.function_graphs = {}
        self.sources_map = {}
        for fgraph in funcGraphs:
            self.function_graphs.update({fgraph.indent: fgraph})

            funcSource = fgraph.source

            if funcSource in self.sources_map:
                srcFuncGraphDict = self.sources_map[funcSource]
                srcFuncGraphDict.update({fgraph.indent: fgraph})
            else:
                srcFuncGraphDict = {fgraph.indent: fgraph}
                self.sources_map.update({funcSource: srcFuncGraphDict})

        self.object_traces = None
        self.program_traces = None

class GCovTraceSummary:
    def __init__(self, funcTraces, objectTraces, programTraces):
        self.func_traces = funcTraces
        self.object_traces = objectTraces
        self.program_traces = programTraces

class GCovFunctionTrace:
    def __init__(self, ident, checksum, counters = None):
        self.indent = ident
        self.check_sum = checksum
        self.counters = counters
        return

    def ApplyArcCounters(self, counters):
        self.counters = counters
        return

class GCovDataCounterBaseRecord:
    """
    """
    def __init__(self, header, counters):
        self.header = header
        self.counters = counters

class GCovDataFunctionAnnouncementRecord():
    """
        header uint32:ident uint32:checksum
    """
    def __init__(self, header, ident, checksum):
        self.header = header
        self.indent = ident
        self.check_sum = checksum
        return

class GCovDataObjectSummaryRecord():
    """"""
    def __init__(self, header, checksum, num, runs, sum, max, summax):
        self.header = header
        self.check_sum = checksum
        self.num = num
        self.runs = runs
        self.sum = sum
        self.max = max
        self.sum_max = summax
        return

class GCovDataProgramSummaryRecord():
    """"""
    def __init__(self, header, checksum, num, runs, sum, max, summax):
        self.header = header
        self.check_sum = checksum
        self.num = num
        self.runs = runs
        self.sum = sum
        self.max = max
        self.sum_max = summax
        return

class GCovDataFile(GCovIO):
    """
    The data file contains the following records.

    [TranslationUnit] [FunctionData]* [Summary:object] [Summary:program*]

        data: {unit function-data* summary:object summary:program*}*

    TranslationUnit: header uint32:checksum

        function-data:    announce_function arc_counts
    announce_function: header uint32:ident uint32:checksum
    arc_counts: header uint64:count*

    summary: uint32:checksum {count-summary}GCOV_COUNTERS
    count-summary:    uint32:num uint32:runs uint64:sum
            uint64:max uint64:sum_max
    """

    def __init__(self, filename=None):
        GCovIO.__init__(self, filename)

        self.trace_summary = None
        return

    def PullRecords(self):
        """
        """
        recordCount = len(self.records)
        rindex = 0

        while rindex < recordCount:
            self.PullRecordAtIndex(rindex)
            rindex += 1

    def PullRecordAtIndex(self, index):
        """
        """
        if self.records is None:
            raise LookupError("GCovNotesFile.PullRecord: You must call GCovDataFile.Load before attempting to pull a record.")

        recCount = len(self.records)
        if index >= recCount:
            raise IndexError("GCovNotesFile.PullRecord: The specified index was out of range.")

        record = self.records[index]
        if isinstance(record, GCovIORecord):
            cpos = 0
            buffer = record.items_data

            swapRecord = GCovDataFile.UnpackRecord(record, self.pack_str32)

            self.records[index] = swapRecord
            del(record)
            record = swapRecord

        return record

    def CreateTraceSummary(self):
        """
        """
        if self.trace_summary is None:
            recordIndex = 0
            recordsLength = len(self.records)

            functionTraces = []
            objectTraces = []
            programTraces = []

            currentTrace = None

            while recordIndex < recordsLength:
                record = self.PullRecordAtIndex(recordIndex)

                tag = record.header.tag

                if tag == GCovIOConst.GCOV_TAG_FUNCTION:
                    if currentTrace is not None:
                        functionTraces.append(currentTrace)
                    currentTrace = GCovFunctionTrace(record.indent, record.check_sum)

                elif tag == GCovIOConst.GCOV_TAG_OBJECT_SUMMARY:
                    if currentTrace is not None:
                        functionTraces.append(currentTrace)
                    currentTrace = None

                    objectTraces.append(record)

                elif tag == GCovIOConst.GCOV_TAG_PROGRAM_SUMMARY:
                    if currentTrace is not None:
                        functionTraces.append(currentTrace)
                    currentTrace = None

                    programTraces.append(record)

                elif tag == GCovIOConst.GCOV_TAG_COUNTER_BASE:
                    currentTrace.ApplyArcCounters(record.counters)
                else:
                    print("Skipping Unknown record type tag=0x%x" % tag)

                recordIndex += 1

            self.trace_summary = GCovTraceSummary(functionTraces, objectTraces, programTraces)

        return self.trace_summary

    @staticmethod
    def UnpackRecord(record, packStr=GCovIOConst.PACKUINT32):
        swapRecord = None
        cpos = 0

        tag = record.header.tag
        header = record.header
        buffer = record.items_data

        if tag == GCovIOConst.GCOV_TAG_FUNCTION:
            swapRecord = GCovDataFile.UnpackFunctionAnnouncement(header, buffer, cpos, packStr)
        elif tag == GCovIOConst.GCOV_TAG_COUNTER_BASE:
            swapRecord = GCovDataFile.UnpackCounterBase(header, buffer, cpos, packStr)
        elif tag == GCovIOConst.GCOV_TAG_OBJECT_SUMMARY:
            swapRecord = GCovDataFile.UnpackObjectSummary(header, buffer, cpos, packStr)
        elif tag == GCovIOConst.GCOV_TAG_PROGRAM_SUMMARY:
            swapRecord = GCovDataFile.UnpackProgramSummary(header, buffer, cpos, packStr)
        else:
            raise IOError("Un-recognized tag (0x%x) found at record index in file." % (tag))

        return swapRecord

    @staticmethod
    def UnpackCounterBase(header, buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
            announce_function: header uint32:ident uint32:checksum string:name string:source uint32:lineno
        """
        cpos = pos

        counterLength = header.length / 2
        counterIndex = 0

        counters = []

        while counterIndex < counterLength:
            nextValue, cpos = GCovIO.UnpackUInt64(buffer, cpos, packStr)
            if nextValue == 386547056640:
                pass
            counters.append(nextValue)
            counterIndex += 1

        rval = GCovDataCounterBaseRecord (header, counters)

        return rval

    @staticmethod
    def UnpackFunctionAnnouncement(header, buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
            announce_function: header uint32:ident uint32:checksum string:name string:source uint32:lineno
        """
        cpos = pos

        ident, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
        checksum, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)

        rval = GCovDataFunctionAnnouncementRecord(header, ident, checksum)

        return rval

    @staticmethod
    def UnpackObjectSummary(header, buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
        """
        cpos = pos

        checksum, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
        num, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
        runs, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
        sum, cpos = GCovIO.UnpackUInt64(buffer, cpos, packStr)
        max, cpos = GCovIO.UnpackUInt64(buffer, cpos, packStr)
        summax, cpos = GCovIO.UnpackUInt64(buffer, cpos, packStr)

        rval = GCovDataObjectSummaryRecord(header, checksum, num, runs, sum, max, summax)

        return rval

    @staticmethod
    def UnpackProgramSummary(header, buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
        """
        cpos = pos
        eob = len(buffer)

        checksum, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
        num, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
        runs, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
        sum, cpos = GCovIO.UnpackUInt64(buffer, cpos, packStr)
        max, cpos = GCovIO.UnpackUInt64(buffer, cpos, packStr)
        summax, cpos = GCovIO.UnpackUInt64(buffer, cpos, packStr)

        rval = GCovDataProgramSummaryRecord(header, checksum, num, runs, sum, max, summax)

        return rval


class GCovGraphArc():
    """
        uint32:dest_block uint32:flags
    """
    def __init__(self, destBlock, flags):
        self.dest_block = destBlock
        self.flags = flags
        self.arc_id = None
        self.counter = None

        self.has_flag_fake = ((flags & GCovIOConst.GCOV_FLAG_ARC_FAKE) > 0)
        self.has_flag_fall_through = ((flags & GCovIOConst.GCOV_FLAG_ARC_FALLTHROUGH) > 0);
        self.has_flag_on_tree = ((flags & GCovIOConst.GCOV_FLAG_ARC_ON_TREE) > 0)

        self.is_relevant_branch = False
        self.is_return_branch = False
        self.is_exception_branch = False

    def Print(self):
        print("        GCovGraphArc:")
        print("            DestBlock=%d" % self.dest_block)
        print("            Flags=%d" % self.flags)
        print("            ArcId=%d" % self.arc_id)
        print("            Counter=%d" % self.counter)
        print("            HasFlagFake=%d" % self.has_flag_fake)
        print("            HasFlagFallThrough=%d" % self.has_flag_fall_through)
        print("            HasFlagOnTree=%d" % self.has_flag_on_tree)
        print("            IsRelevantBranch=" + self.is_relevant_branch)
        print("            IsExceptionBranch=" + self.is_exception_branch)

        return

class GCovGraphLine():
    """
        uint32:line_no string:(filename | linestr | NULL)
    """
    def __init__(self, number, content):
        self.number = number
        self.content = content

    def Print(self):
        print("        GCovGraphLine:")
        print("            Number=%d" % self.number)
        print("            Content=%s" % str(self.content))
        return

class GCovGraphBlock():
    """
    """
    def __init__(self, blockNumber, flags):
        self.block_number = blockNumber
        self.flags = flags
        self.lines = None
        self.line_no = 0

        self.arcs_successors = []
        self.arcs_Predecessors = []

        self.is_branch_landing = False
        self.is_call_site = False
        self.is_loop = False
        self.is_exception_landing = False
        self.is_return_landing = False
        self.has_relevant_branches = False

    def Print(self):
        print("    GCovGraphBlock (%d):" % self.block_number)
        print("        Flags=%x" % self.flags)
        print("        HasRelevantBranches=" + self.has_relevant_branches)

        if self.lines is not None:
            for line in self.lines:
                line.Print()
            print("")

        return

class GCovGraphFunction():
    """
        note: unit function-graph*
          unit: header uint32:checksum string:source
          function-graph: announce_function basic_blocks {arcs | lines}*
    """
    def __init__(self, functionAnnouncement):
        self.indent = functionAnnouncement.indent
        self.check_sum = functionAnnouncement.check_sum
        self.name = functionAnnouncement.name
        self.source = functionAnnouncement.source
        self.orig_source = self.source
        self.line_no = functionAnnouncement.line_no
        self.blocks = None
        self.block_count = 0
        self.execution_count = 0

        self.has_catch = False

        self.solved = False

        return

    def Print(self):
        print("===================================================================")
        print("GCovGraphFunction:")
        print("    Ident=%d" % self.indent)
        print("    CheckSum=0x%x" % self.check_sum)
        print("    Name=%s" % self.name)
        print("    Source=%s" % self.source)
        print("    LineNo=%d" % self.line_no)
        print("")

        for blk in self.blocks:
            blk.Print()

        print("===================================================================")
        print("")

    def ApplyArcSet(self, arcset, nextArcId):

        fromBlockNumber = arcset.block_number

        fromBlock = self.blocks[fromBlockNumber]
        fromBlock.arcs_successors = arcset.arcs

        for arcTo in arcset.arcs:
            arcTo.arc_id = nextArcId
            nextArcId += 1

            toBlockNumber = arcTo.dest_block
            toBlock = self.blocks[toBlockNumber]
            toBlock.arcs_Predecessors.append(arcTo)

        return nextArcId

    def ApplyCounters(self, counters):
        counterIndex = 0
        for block in self.blocks:
            for arc in block.arcs_successors:
                if (arc.flags & GCovIOConst.GCOV_FLAG_ARC_FAKE) == 0 and \
                  (arc.flags & GCovIOConst.GCOV_FLAG_ARC_ON_TREE) == 0:
                    if arc.counter is None:
                        arc.counter = 0
                    counterVal = counters[counterIndex]
                    arc.counter += counterVal
                    counterIndex += 1

        if counterIndex != len(counters):
            print("WARNING: Not all of the counters were used.")

        return

    def ApplyLineSet(self, lineset):

        blockNumber = lineset.block_number

        block = self.blocks[blockNumber]
        block.lines = lineset.lines

        return

    def ApplyBasicBlock(self, basicBlock):

        blockNumber = 0
        blockCount = len(basicBlock.flagset)

        self.blocks = []

        while(blockNumber < blockCount):
            blockFlags = basicBlock.flagset[blockNumber]

            block = GCovGraphBlock(blockNumber, blockFlags)
            self.blocks.append(block)

            blockNumber += 1

        self.block_count = blockCount

        if self.block_count > 0:
            pass

        return

    def ResetCounters(self):
        counterIndex = 0
        for block in self.blocks:
            for arc in block.arcs_successors:
                arc.counter = None
        return

    def ResetUnknowns(self):
        counterIndex = 0
        for block in self.blocks:
            for arc in block.arcs_successors:
                if (arc.flags & GCovIOConst.GCOV_FLAG_ARC_FAKE) != 0 or \
                  (arc.flags & GCovIOConst.GCOV_FLAG_ARC_ON_TREE) != 0:
                    arc.counter = None
        return

    WALKSTATE_NONE = 0
    WALKSTATE_BRANCHCHAIN = 1

    WALKSTATE_STRINGS = ["WALKSTATE_NONE", "WALKSTATE_BRANCHCHAIN"]

    def SetPostProcessedFields(self):

        vprint ("Post Processing Graph for '%s'" % self.name)

        if (self.name == "_sputc"):
            pass

        blocksList = self.blocks
        blocksLen = len(self.blocks)

        lastBlockNo = blocksLen - 1
        lastBlock = blocksList[lastBlockNo]

        blockIndex = 0

        fakePredCount = 0
        for parc in lastBlock.arcs_Predecessors:
            if parc.has_flag_fake:
                fakePredCount = fakePredCount + 1

        exceptionBlock = None
        exceptionBlockNo = None

        if fakePredCount >= (len(lastBlock.arcs_Predecessors) - 1):
            exceptionBlock = lastBlock
            exceptionBlock.is_exception_landing = True
            exceptionBlockNo = lastBlockNo

        returnBlock = None
        returnBlockNo = None

        if fakePredCount == 0:
            returnBlock = lastBlock
            returnBlock.is_return_landing = True
            returnBlockNo = lastBlockNo
        else:
            returnBlockNo = lastBlockNo - 1
            returnBlock = blocksList[returnBlockNo]
            returnBlock.is_return_landing = True

        # -------------------------------------------------------------------------
        # Find and mark all the call site blocks and all the branches that are 
        # return branches
        # -------------------------------------------------------------------------
        while(blockIndex < blocksLen):
            nxtBlock = blocksList[blockIndex]

            succLen = len(nxtBlock.arcs_successors)
            predLen = len(nxtBlock.arcs_Predecessors)

            setCallBranch = False

            for sarc in nxtBlock.arcs_successors:
                destBlockNo = sarc.dest_block
                if sarc.has_flag_fake and (exceptionBlock is not None) and (destBlockNo == exceptionBlock.block_number):
                    sarc.is_exception_branch = True
                    nxtBlock.is_call_site = True
                    setCallBranch = True

                if sarc.dest_block == returnBlockNo:
                    sarc.is_return_branch = True

            noFakePredArcs = True
            for parc in nxtBlock.arcs_Predecessors:
                if parc.has_flag_fake:
                    noFakePredArcs = False

            if (predLen > 1) and noFakePredArcs:
                nxtBlock.is_branch_landing = True

            blockIndex += 1

        # -------------------------------------------------------------------------
        # Find and mark all the blocks that have relevant branches
        # -------------------------------------------------------------------------
        blockIndex = 0

        walkStack = []
        walkState = GCovGraphFunction.WALKSTATE_NONE

        nxtBlock = None
        prevBlock = None

        while(blockIndex < blocksLen):
            prevBlock = nxtBlock
            nxtBlock = blocksList[blockIndex]

            vprint ("Block(%d) - %s" % (blockIndex, GCovGraphFunction.WALKSTATE_STRINGS[walkState]))

            hasLines = False
            if (nxtBlock.lines is not None) and (len(nxtBlock.lines) > 0):
                hasLines = True

            successorCount = len(nxtBlock.arcs_successors)

            #-------------------------------------------------------------------------------
            # This path is for processing sequences that began with a call-site
            #-------------------------------------------------------------------------------
            if walkState == GCovGraphFunction.WALKSTATE_BRANCHCHAIN:
                if hasLines or successorCount < 2:
                    if len(walkStack) > 0:
                        if not prevBlock.is_call_site:
                            will_branch = len(prevBlock.arcs_successors) > 1

                            if will_branch:
                                while(True):
                                    if len(walkStack) == 0:
                                        break

                                    sidx, sblk = walkStack.pop()

                                    sblk.has_relevant_branches = True
                                    for arc in sblk.arcs_successors:
                                        arc.is_relevant_branch = True
                                    #end while(True):
                        else:
                            while(True):
                                if len(walkStack) == 0:
                                    break

                                sidx, sblk = walkStack.pop()
                                #end while(True):
                    walkStack = []
                    walkState = GCovGraphFunction.WALKSTATE_NONE
                else:
                    walkStack.append((blockIndex, nxtBlock))

            #-------------------------------------------------------------------------------
            # This path initiates the start of the processing of a decision chain
            #-------------------------------------------------------------------------------
            if walkState == GCovGraphFunction.WALKSTATE_NONE:
                #---------------------------------------------------------------------------------
                # If a block has lines and has more than one successor arc, it must be the start
                # of a relevant branch chain.
                #---------------------------------------------------------------------------------
                if hasLines:
                    if (successorCount > 1):
                            walkState = GCovGraphFunction.WALKSTATE_BRANCHCHAIN
                            walkStack.append((blockIndex, nxtBlock))
                    else:
                        walkState = GCovGraphFunction.WALKSTATE_NONE
                else:
                    if (successorCount > 1):
                        isloop = False
                        for arc in nxtBlock.arcs_successors:
                            if arc.dest_block < blockIndex:
                                isloop = True

                        if isloop:
                            nxtBlock.is_loop = True
                    else:
                        walkState = GCovGraphFunction.WALKSTATE_NONE

            blockIndex += 1

        vprint ("")
        vprint ("")

        return

    def SolveGraph(self):
        """
                 Solves the function graph for the missing arc counts using the counts provided to ApplyCounters.  SolveGraph 
            requires that at least one call to ApplyCounters has been made with the correct counter data.  You can make reapeated
            calls to ApplyCounters to apply multiple counter data sets.  Then call SolveGraph to solve the graph.  To empty the
            graph counters use ResetCounters.
        """

        block = None

        #Next solve the graph for the unknown counters
        revisitList = []
        revisitList.extend(self.blocks)

        lastRevisitCount = 0
        blocksToSolve = []

        while(True):

            if (len(blocksToSolve) == 0):
                revisitCount = len(revisitList)

                if (revisitCount > 0):
                    if (revisitCount == lastRevisitCount):
                        raise IndexError("ERROR: Unsolvable function graph.")

                    lastRevisitCount = revisitCount

                    blocksToSolve = revisitList
                    revisitList = []
                else:
                    break

            block = blocksToSolve.pop()

            predecessorUnknown = 0
            successorUnknown = 0

            predecessorCount = len(block.arcs_Predecessors)
            successorCount = len(block.arcs_successors)

            for arc in block.arcs_Predecessors:
                if arc.counter is None:
                    predecessorUnknown += 1

            for arc in block.arcs_successors:
                if arc.counter is None:
                    successorUnknown += 1

            # If a block has no predecessors or no successors we have to solve its arc counts from another block, no need to revisit
            if (predecessorCount == 0) or (successorCount == 0):
                pass

            # If a block has an unknown on both sides then put the block in the revisit list
            elif ((predecessorUnknown > 0) and (successorUnknown > 0)):
                revisitList.append(block)

            # If a block only has one unknown and it is an unknown predecessor then solve it here
            elif (predecessorUnknown == 1):
                succSum = 0
                for arc in block.arcs_successors:
                    succSum += arc.counter

                predSum = 0

                unknownArc = None
                for arc in block.arcs_Predecessors:
                    if arc.counter is None:
                        unknownArc = arc
                    else:
                        predSum += arc.counter

                unknownArc.counter = succSum - predSum

            # If a block only has one unknown and it is an unknown successsor then solve it here
            elif successorUnknown == 1:
                predSum = 0
                for arc in block.arcs_Predecessors:
                    predSum += arc.counter

                succSum = 0

                unknownArc = None
                for arc in block.arcs_successors:
                    if arc.counter is None:
                        unknownArc = arc
                    else:
                        succSum += arc.counter

                unknownArc.counter = predSum - succSum

            # Otherwise the block has two unsolved arcs on one side of the block, push it to the revisit list
            else:
                revisitList.append(block)

            #end while(True)
        blocksLen = len(self.blocks)
        if blocksLen > 0:
            self.execution_count = 0

            executionCount = 0

            entryBlock = self.blocks[0]
            for arc in entryBlock.arcs_successors:
                arcCounter = arc.counter
                executionCount += arcCounter

            self.execution_count = executionCount

        self.solved = True

        return sum

    @staticmethod
    def HasRelevantDescendantBlock_CallChain(blockList, blockListLen, block, blockIndex):

        isRelevant = False

        followOnBlock = None
        followOnBlockNo = None

        for sarc in block.arcs_successors:
            if not sarc.has_flag_fake:
                followOnBlockNo = sarc.dest_block
                followOnBlock = blockList[followOnBlockNo]

        if (followOnBlock is not None):
            if followOnBlock.is_call_site:
                if (followOnBlock.lines is None) or (len(followOnBlock.lines) == 0):
                    isRelevant = GCovGraphFunction.HasRelevantDescendantBlock_CallChain(blockList, blockListLen, followOnBlock, followOnBlockNo)
            else:
                if len(followOnBlock.arcs_successors) > 1:
                    isRelevant = True

            if isRelevant:
                followOnBlock.has_relevant_branches = True
                for sarc in followOnBlock.arcs_successors:
                    sarc.is_relevant_branch = True

        return isRelevant

    @staticmethod
    def HasRelevantDescendantBlock_Else(blockList, blockListLen, block, blockIndex):

        isRelevant = False

        followOnBlock = None
        followOnBlockNo = None

        for sarc in block.arcs_successors:
            if not sarc.has_flag_fake:
                followOnBlockNo = sarc.dest_block
                followOnBlock = blockList[followOnBlockNo]

        if (followOnBlock is not None):
            if followOnBlock.is_call_site:
                if (followOnBlock.lines is None) or (len(followOnBlock.lines) == 0):
                    isRelevant = GCovGraphFunction.HasRelevantDescendantBlock_CallChain(blockList, blockListLen, followOnBlock, followOnBlockNo)
            else:
                if len(followOnBlock.arcs_successors) > 1:
                    isRelevant = True

            if isRelevant:
                followOnBlock.has_relevant_branches = True
                for sarc in followOnBlock.arcs_successors:
                    sarc.is_relevant_branch = True

        return isRelevant

class GCovNotesArcSetRecord():
    """
        arcs: header uint32:block_no arc*
    """
    def __init__(self, header, blockNumber, arcs):
        self.header = header
        self.block_number = blockNumber
        self.arcs = arcs

    def Print(self):
        print("ArcsRecord: BlockNumber=%d" % self.block_number)
        return

class GCovNotesLineSetRecord():
    """
        lines: header uint32:block_no line* => termline
            line:  uint32:line_no | uint32:0 string:filename
            termline: uint32:0 string:NULL
    """
    def __init__(self, header, blockNumber, lines):
        self.header = header
        self.block_number = blockNumber
        self.lines = lines

    def Print(self):
        print("LinesRecord: BlockNumber=%d" % self.block_number)
        return

class GCovNotesBasicBlocksRecord():
    def __init__(self, header, flagSet):
        self.header = header
        self.flagset = flagSet
        return

    def Print(self):
        blockCount = len(self.flagset)
        print("BasicBlock: BlockCount=%d" % (blockCount))
        return

class GCovNotesFunctionAnnouncementRecord():
    """
        header uint32:ident uint32:checksum string:name string:source uint32:lineno
    """
    def __init__(self, header, ident, checksum, name, source, lineno):
        self.header = header
        self.indent = ident
        self.check_sum = checksum
        self.name = name
        self.source = source
        self.line_no = lineno
        return

    def Print(self):
        print("Function: Ident=%d CheckSum=%d LineNo=%d Name=%s Source%s" % (self.indent, self.check_sum, self.line_no, self.name, self.source))
        return

class GCovNotesFile(GCovIO):
    """
        The BASIC_BLOCK record holds per-bb flags.  The number of blocks
        can be inferred from its data length.  There is one ARCS record per
        basic block.  The number of arcs from a bb is implicit from the
        data length.  It enumerates the destination bb and per-arc flags.
        There is one LINES record per basic block, it enumerates the source
        lines which belong to that basic block.  Source file names are
        introduced by a line number of 0, following lines are from the new
        source file.  The initial source file for the function is NULL, but
        the current source file should be remembered from one LINES record
        to the next.  The end of a block is indicated by an empty filename
        - this does not reset the current source file.  Note there is no
        ordering of the ARCS and LINES records: they may be in any order,
        interleaved in any manner.  The current filename follows the order
        the LINES records are stored in the file, *not* the ordering of the
        blocks they are for.

    """

    def __init__(self, filename=None):
        GCovIO.__init__(self, filename)
        self.graphs = None
        return

    def PullRecords(self):

        recordCount = len(self.records)
        rindex = 0

        while(rindex < recordCount):
            self.PullRecordAtIndex(rindex)
            rindex += 1

    def PullRecordAtIndex(self, index):
        if self.records is None:
            raise LookupError("GCovNotesFile.PullRecord: You must call GCovDataFile.Load before attempting to pull a record.")

        recCount = len(self.records)
        if index >= recCount:
            raise IndexError("GCovNotesFile.PullRecord: The specified index was out of range.")

        record = self.records[index]
        if isinstance(record, GCovIORecord):
            cpos = 0
            buffer = record.items_data

            swapRecord = GCovNotesFile.UnpackRecord(record, self.pack_str32)

            self.records[index] = swapRecord
            del(record)
            record = swapRecord

        return record

    def PullGraphs(self, refresh=False):

        if self.graphs is None or refresh == True:
            recordIndex = 0
            recordsLength = len(self.records)

            functionGraphs = []
            currentGraph = None
            nextArcId = 0

            while(recordIndex < recordsLength):
                record = self.PullRecordAtIndex(recordIndex)

                tag = record.header.tag

                if tag == GCovIOConst.GCOV_TAG_FUNCTION:
                    nextArcId = 0

                    currentGraph = GCovGraphFunction(record)
                    functionGraphs.append(currentGraph)

                    vprint ("Processing function '%s' ident '%d'" % (currentGraph.name, currentGraph.indent))

                else:
                    if currentGraph is not None:
                        if tag == GCovIOConst.GCOV_TAG_BLOCKS:
                            currentGraph.ApplyBasicBlock(record)
                        elif tag == GCovIOConst.GCOV_TAG_ARCS:
                            nextArcId = currentGraph.ApplyArcSet(record, nextArcId)
                        elif tag == GCovIOConst.GCOV_TAG_LINES:
                            currentGraph.ApplyLineSet(record)
                        else:
                            print("WARNING: Skipping Unknown record type tag=0x%x" % tag)
                    else:
                        print("WARNING: Skipping un-announce function record of type tag=0x%x" % tag)

                recordIndex += 1

            # Go through the function graphs and set the context inferred fields
            for currentGraph in functionGraphs:
                currentGraph.SetPostProcessedFields()

            self.graphs = functionGraphs

        return self.graphs

    @staticmethod
    def UnpackRecord(record, packStr=GCovIOConst.PACKUINT32):
        swapRecord = record
        cpos = 0

        tag = record.header.tag
        header = record.header
        buffer = record.items_data

        if tag == GCovIOConst.GCOV_TAG_FUNCTION:
            swapRecord = GCovNotesFile.UnpackFunctionAnnouncement(header, buffer, cpos, packStr)
        elif tag == GCovIOConst.GCOV_TAG_ARCS:
            swapRecord = GCovNotesFile.UnpackArcSet(header, buffer, cpos, packStr)
        elif tag == GCovIOConst.GCOV_TAG_LINES:
            swapRecord = GCovNotesFile.UnpackLineSet(header, buffer, cpos, packStr)
        elif tag == GCovIOConst.GCOV_TAG_BLOCKS:
            swapRecord = GCovNotesFile.UnpackBasicBlock(header, buffer, cpos, packStr)
        else:
            raise IOError("Un-recognized tag (0x%x) found in file." % (tag))

        return swapRecord

    @staticmethod
    def UnpackArcSet(header, buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
            arcs: header uint32:block_no arc*
                arc:  uint32:dest_block uint32:flags
        """
        cpos = pos
        eob = len(buffer)

        blockNumber, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)

        arcCount = (eob - 4) / 8
        arcSet = []

        while arcCount > 0:
            destblock, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
            flags, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)

            arcEntry = GCovGraphArc(destblock, flags)
            arcSet.append(arcEntry)

            arcCount -= 1

        rval = GCovNotesArcSetRecord(header, blockNumber, arcSet)

        return rval

    @staticmethod
    def UnpackBasicBlock(header, buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
            header uint32:flags*
        """
        cpos = pos
        eob = len(buffer)

        flagCount = header.length
        flagSet = []
        while flagCount > 0:
            flags, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
            flagSet.append(flags)

            flagCount -= 1

        rval = GCovNotesBasicBlocksRecord(header, flagSet)

        return rval

    @staticmethod
    def UnpackFunctionAnnouncement(header, buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
            announce_function: header uint32:ident uint32:checksum string:name string:source uint32:lineno
        """
        cpos = pos

        ident, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)
        checksum, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)

        name, cpos = GCovIO.UnpackString(buffer, cpos, packStr)
        source, cpos = GCovIO.UnpackString(buffer, cpos, packStr)

        lineno, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)

        rval = GCovNotesFunctionAnnouncementRecord(header, ident, checksum, name, source, lineno)

        return rval

    @staticmethod
    def UnpackLineSet(header, buffer, pos, packStr=GCovIOConst.PACKUINT32):
        """
                lines: header uint32:block_no line* => termline

            A unpacked line could look like any of the below items.  It is simply a uint32 followed by a string

                line:  uint32:0 string:filename
                       uint32:line_no
                       uint32:0, string:NULL
        """
        cpos = pos

        blockNumber, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)

        lineset = []

        while True:
            lineno, cpos = GCovIO.UnpackUInt32(buffer, cpos, packStr)

            if lineno == 0:
                linestr, cpos = GCovIO.UnpackString(buffer, cpos, packStr)

            if (lineno == 0) and (linestr is None):
                break

            lineitem = GCovGraphLine(lineno, linestr)
            lineset.append(lineitem)

        rval = GCovNotesLineSetRecord(header, blockNumber, lineset)
        return rval

class GCovScanContext:

    def __init__(self, includeFilters, excludeFilters):
        self.include_filters = includeFilters
        self.exclude_filters = excludeFilters
        self.files_found = []

class GCovProcessor:

    def __init__(self, basePathDataList = None, basePathGraphList=None, basePathCodeList=None, 
                 basePathIncludeList=None, includeFilter=None, excludeFilter=None):
        self.base_path_data_list = basePathDataList
        self.base_path_graph_list = basePathGraphList
        self.base_path_code_list = basePathCodeList
        self.base_path_include_list = basePathIncludeList

        self.include_filters = []
        self.exclude_filters = []

        if includeFilter is not None:
            self.include_filters = includeFilter.split(':')

        if excludeFilter is not None:
            self.exclude_filters = excludeFilter.split(':')

        self.coverage_map = {}

        return

    def AddBasePathCode(self, path):
        if self.base_path_code_list is None:
            self.base_path_code_list = []

        self.base_path_code_list.append(path)

        return

    def AddBasePathData(self, path):
        if self.base_path_data_list is None:
            self.base_path_data_list = []

        self.base_path_data_list.append(path)

        return

    def AddBasePathGraph(self, path):
        if self.base_path_graph_list is None:
            self.base_path_graph_list = []

        self.base_path_graph_list.append(path)

        return

    def AddBasePathInclude(self, path):
        if self.base_path_include_list is None:
            self.base_path_include_list = []

        self.base_path_include_list.append(path)

        return

    def GenerateTraceFile(self, traceFilename, testname=None):
        """
            TODO: Code the generate output method
        """
        traceFile = None

        try:
            traceFile = open(traceFilename, 'w')

            infoWriter = GCovInfoFileWriter(traceFile, testname)

            for coverageMapItem in self.coverage_map.values():
                infoWriter.WriteSourcefileSection(coverageMapItem)

        finally:
            if traceFile is not None:
                traceFile.close()

        return

    def PopulateCoverageMap(self, reset=True):

        if reset:
            self.Reset()

        for basePathData in self.base_path_data_list:
            absBasePathData = os.path.abspath(basePathData)

            scanContext = GCovScanContext(self.include_filters, self.exclude_filters)

            for currentDir, dirList, fileList in os.walk(absBasePathData):
                self._Scan_For_DataFiles(scanContext, currentDir, fileList)

            dataFileList = scanContext.files_found

            #Process all the data files
            for dataFilePath, dataFileName in dataFileList:
                self._Process_DataFile(absBasePathData, dataFilePath, dataFileName)

            #Go through all of the coverage map items and resolve the unknown counts
            for key in self.coverage_map.keys():
                coverageitem = self.coverage_map[key]
                for funcGraph in coverageitem.function_graphs.values():
                    try:
                        funcGraph.SolveGraph()
                    except:
                        pass

        return

    def Reset(self):

        for key in self.coverage_map.keys():
            item = self.coverage_map.pop(key)
            del(item)

        return

    def _Export_TraceFile(self, dataFileLeaf):
        """
            TODO: Continue implementing this method
        """
        df_leaf, df_ext = os.path.splitext(dataFileLeaf)

        #Open the .info file
        infoFilePath = os.path.join(self._BasePathData, df_leaf + ".info")
        info_fh = None

        coverageMap = None

        with open(infoFilePath, 'w') as info_fh:
            #Go through the coverage map items and write the information to the info file
            for cmitem in coverageMap.Items:
                traceWriter = GCovInfoFileWriter("NA")

                traceWriter.WriteTo(info_fh)

        return

    def _LocateGraphFile(self, df_fullbase, df_leafbase):
        foundfile = None

        if self.base_path_graph_list is not None:
            for basePath in self.base_path_graph_list:
                absBasePath = os.path.abspath(basePath)
                nxt_filename = os.path.join(absBasePath, df_leafbase + ".gcno")

                if os.path.exists(nxt_filename) and os.path.isfile(nxt_filename):
                    foundfile = nxt_filename
                    break
        else:
            nxt_filename = df_fullbase + ".gcno"

            if os.path.exists(nxt_filename) and os.path.isfile(nxt_filename):
                foundfile = nxt_filename

        return foundfile

    def _LocateSourceFile(self, df_fullbase, df_leafbase, c_file):
        foundfile = None

        if os.path.isabs(c_file) and os.path.exists(c_file) and os.path.isfile(c_file):
            foundfile = c_file
        else:
            c_dir = os.path.dirname(c_file)

            if c_dir != "":
                # If c_file has a relative path then do a search as follows:
                #    1. Look in the code path list by appending c_file to each path
                #    2. Look in the data path list by appending c_file to each path 
                if self.base_path_code_list is not None:
                    for basePath in self.base_path_code_list:
                        nxt_filename = os.path.join(basePath, c_file)
                        nxt_filename = os.path.abspath(nxt_filename)

                        if os.path.exists(nxt_filename) and os.path.isfile(nxt_filename):
                            foundfile = nxt_filename
                            break

                if foundfile is None:
                    for basePath in self.base_path_data_list:
                        nxt_filename = os.path.join(basePath, c_file)
                        nxt_filename = os.path.abspath(nxt_filename)

                        if os.path.exists(nxt_filename) and os.path.isfile(nxt_filename):
                            foundfile = nxt_filename
                            break
            else:
                # If c_file is just a filename with no directory do a search as follows:
                #    1. Look in the code path list in the same leaf directory as the data file
                #    2. Look in the data path list in the same leaf directory as the data file
                #    3. Look in the include path list without appending the leaf of the data file
                df_dir = os.path.dirname(df_leafbase)

                chk_file = os.path.join(df_dir, c_file)

                if self.base_path_code_list is not None:
                    for basePath in self.base_path_code_list:
                        absBasePath = os.path.abspath(basePath)
                        nxt_filename = os.path.join(absBasePath, chk_file)
                        nxt_filename = os.path.abspath(nxt_filename)

                        if os.path.exists(nxt_filename) and os.path.isfile(nxt_filename):
                            foundfile = nxt_filename
                            break

                if foundfile is None:
                    for basePath in self.base_path_data_list:
                        absBasePath = os.path.abspath(basePath)
                        nxt_filename = os.path.join(absBasePath, chk_file)
                        nxt_filename = os.path.abspath(nxt_filename)

                        if os.path.exists(nxt_filename) and os.path.isfile(nxt_filename):
                            foundfile = nxt_filename
                            break

                if (foundfile is None) and (self.base_path_include_list is not None):
                    for basePath in self.base_path_include_list:
                        absBasePath = os.path.abspath(basePath)
                        nxt_filename = os.path.join(absBasePath, c_file)
                        nxt_filename = os.path.abspath(nxt_filename)

                        if os.path.exists(nxt_filename) and os.path.isfile(nxt_filename):
                            foundfile = nxt_filename
                            break

        # Remove any base relative '/base/../../file' references from the path. 'os.path.isabs' still considers these absolute.
        if foundfile is not None:
            foundfile = os.path.abspath(foundfile)

        return foundfile

    def _Process_DataFile(self, basePathData, dataFileDir, dataFileName):

        #Break the dataFileLeaf path into its components
        df_base, df_ext = os.path.splitext(dataFileName)

        df_fullpathfile = os.path.join(dataFileDir, dataFileName)
        df_leafpathfile = df_fullpathfile[len(basePathData) + 1:]

        df_fullbasefile = os.path.join(dataFileDir, df_base)
        df_leafbasefile = df_fullbasefile[len(basePathData) + 1:]

        coverageItem = None

        if df_leafpathfile not in self.coverage_map:
            #Pull in the GCNO graph for the data file
            graphFilename = self._LocateGraphFile(df_fullbasefile, df_leafbasefile)
            if graphFilename is not None:
                gf = GCovNotesFile(graphFilename)
                gf.Load()

                funcGraphs = gf.PullGraphs()

                #Go through the function graphs and locate the source files
                for fgraph in funcGraphs:
                    sourceFile = self._LocateSourceFile(df_fullbasefile, df_leafbasefile, fgraph.source)
                    if (sourceFile is not None) and os.path.exists(sourceFile):
                        fgraph.source = sourceFile

                coverageItem = GCovCoverageMapItem(df_leafpathfile, funcGraphs)

                self.coverage_map[df_leafpathfile] = coverageItem
            else:
                #raise IOError("Could not locate gcno file for datafile=%s" % df_leafpathfile)
                print("Could not locate gcno file for datafile=%s" % df_leafpathfile)

        else:
            coverageItem = self.coverage_map[df_leafpathfile]

        if coverageItem is not None:
            #Process the data file and store the counters in coverage map
            df = GCovDataFile(df_fullpathfile)
            df.Load()

            traceSummary = df.CreateTraceSummary()

            functionGraphs = coverageItem.function_graphs

            for funcTrace in traceSummary.func_traces:
                funcIdent = funcTrace.indent

                if funcIdent in functionGraphs:
                    funcGraph = functionGraphs[funcIdent]
                    funcGraph.ApplyCounters(funcTrace.counters)
                else:
                    print("Function Identity (%s) not found..." % funcIdent)

            coverageItem.object_traces = traceSummary.object_traces
            coverageItem.program_traces = traceSummary.program_traces

        return

    def _Scan_For_DataFiles(self, scanContext, currentDir, fileList):

        filesFound = scanContext.files_found

        for filename in fileList:
            f_base, f_ext = os.path.splitext(filename)
            if f_ext == ".gcda":
                filesFound.append((currentDir, filename))

        return True

    def _Scan_For_GraphFiles(self, scanContext, currentDir, fileList):

        filesFound = scanContext.files_found

        for filename in fileList:
            f_base, f_ext = os.path.splitext(filename)
            if f_ext == ".gcno":
                filesFound.append((currentDir, filename))

        return

def operation_capture(cmdOptions, cmdArgs):
    """
    """
    dataBasePathList = cmdOptions.DATAPATHS
    if (dataBasePathList is None) or (len(dataBasePathList) == 0):
        raise OptParseError("You must specify at least one data source path to run a capture operation.")

    for chkpath in dataBasePathList:
        if not os.path.exists(chkpath):
            raise OptParseError("The directory specified as the data path does not exist. path=%s" % chkpath)

    graphBasePathList = None
    if cmdOptions.GRAPHPATHS is not None:
        graphBasePathList = cmdOptions.GRAPHPATHS

        for chkpath in graphBasePathList:
            if not os.path.exists(chkpath):
                raise OptParseError("The directory specified as the graph path does not exist. path=%s" % chkpath)

    sourceBasePathList = None
    if cmdOptions.SOURCEPATHS is not None:
        sourceBasePathList = cmdOptions.SOURCEPATHS

        for chkpath in sourceBasePathList:
            if not os.path.exists(chkpath):
                raise OptParseError("The directory specified as the source code path does not exist. path=%s" % chkpath)

    includeFilter = "*"
    if cmdOptions.INCLUDEPATTERNS is not None:
        includeFilter = cmdOptions.INCLUDEPATTERNS

    excludeFilter = ""
    if cmdOptions.EXCLUDEPATTERNS is not None:
        includeFilter = cmdOptions.EXCLUDEPATTERNS

    if cmdOptions.OUTPUTFILE is None:
        raise OptParseError("An output file must be specified for the --capture operation.")

    tracefileName = os.path.abspath(cmdOptions.OUTPUTFILE)

    #Make sure the parent directory of the output tracefile exists
    traceDir = os.path.dirname(tracefileName)
    if not os.path.exists(traceDir):
        os.makedirs(traceDir)

    gcov_proc = GCovProcessor(dataBasePathList, graphBasePathList, sourceBasePathList, None, includeFilter, excludeFilter)#

    gcov_proc.PopulateCoverageMap()

    gcov_proc.GenerateTraceFile(tracefileName)

    print("")
    print("Capture Completed...")

    return

def operation_merge(cmdOptions, cmdArgs):

    return

def operation_parse(cmdOptions, cmdArgs):
    if len(cmdArgs) <= 0:
        raise OptParseError("The '--parse' option requires at least one gcov file as an arguement.")

    for parseFile in cmdArgs:

        fileRoot, fileExt = os.path.splitext(parseFile)
        filePath = os.path.abspath(parseFile)

        if fileExt == ".gcno":
            print("Processing .gcno file...")

            gcnoFile = GCovNotesFile()
            gcnoFile.Load(filePath)

            gcnoFile.PullRecords()

            for record in gcnoFile.records:
                record.Print()

            graphSet = gcnoFile.PullGraphs()

            for graph in graphSet:
                graph.Print()

            print("")

        elif fileExt == ".gcda":
            print("Processing .gcda file...")

            gcdaFile = GCovDataFile()
            gcdaFile.Load(filePath)

            gcdaFile.PullRecords()

            for record in gcdaFile.records:
                print(str(record))
        else:
            print("Unknown extension '%s'" % fileExt)

    return

def operation_remove(cmdOptions, cmdArgs):

    return

def operation_zerocounters(cmdOptions, cmdArgs):

    return

def validate_operation_count(cmdOptions, cmdArgs):
    # Make sure that at least one operation was specified
    operationCount = 0

    if cmdOptions.CAPTURE:
        operationCount += 1
    if cmdOptions.MERGE:
        operationCount += 1
    if cmdOptions.PARSE:
        operationCount += 1
    if cmdOptions.REMOVE is not None:
        operationCount += 1
    if cmdOptions.ZEROCOUNTERS:
        operationCount += 1

    if (operationCount == 0) or (operationCount > 1):
        raise OptionError("You must specify just one Operation option. operationCount=%d" % operationCount, "--parse")

    return

def validate_options(cmdOptions, cmdArgs):

    validate_operation_count(cmdOptions, cmdArgs)

    return

def pycover_main():

    print

    cmdUsage = "usage: %prog [options] arg1 arg2"

    optParser = OptionParser(cmdUsage)

    optGrpMisc = OptionGroup(optParser, "Miscellaneous")
    optGrpMisc.add_option("-v", "--version", dest="version", action="store_true", help="Prints out the version then exits.")
    optGrpMisc.add_option("-q", "--quiet", dest="verbose", action="store_false", help="Turn off verbose logging")
    optParser.add_option_group(optGrpMisc)

    optGrpOperations = OptionGroup(optParser, "Operations")
    optGrpOperations.add_option("-c", "--capture", dest="CAPTURE", action="store_true", help="Capture coverage data.")
    optGrpOperations.add_option("-m", "--merge", dest="MERGE", action="store_true", help="Merge all trace files into a single trace file.")
    optGrpOperations.add_option("-r", "--remove", dest="REMOVE", action="store_true", help="Remove traces from a trace file.")
    optGrpOperations.add_option("-z", "--zerocounters", dest="ZEROCOUNTERS", action="store_true", help="Reset all execution counts to zero.")
    optGrpOperations.add_option("--parse", dest="PARSE", action="store_true", help="Parse the specified file and print the contents to the console in a legible form.")
    optParser.add_option_group(optGrpOperations)

    optGrpOptions = OptionGroup(optParser, "Modifiers")
    optGrpOptions.add_option("-d", "--data-path", dest="DATAPATHS", action="append", help="Add path to a list of paths to scan for trace data files (.gcda files).")
    optGrpOptions.add_option("-s", "--source-path", dest="SOURCEPATHS", action="append", help="Add path to a list of paths to scan for source code files.")
    optGrpOptions.add_option("-g", "--graph-path", dest="GRAPHPATHS", action="append", help="Add path to a list of paths to scan for graph information files (.gcno files).")
    optGrpOptions.add_option("-x", "--extended-path", dest="EXTENDEDPATHS", action="append", help="Add path to a list of directories to scan for source files and header files.")
    optGrpOptions.add_option("-i", "--include-patterns", dest="INCLUDEPATTERNS", action="store", help="A semi-colon seperated list of patterns that are used while scanning for trace data files.")
    optGrpOptions.add_option("-e", "--exclude-patterns", dest="EXCLUDEPATTERNS", action="store", help="A semi-colon seperated list of patterns that are used while scanning for trace data files.")
    optGrpOptions.add_option("-o", "--output-file", dest="OUTPUTFILE", action="store", help="Write data to FILENAME instead of stdout.")

    optGrpOptions.add_option("--subtract", dest="SUBTRACTFILE", action="store", help="Subtract trace file.")
    optGrpOptions.add_option("--checksum", dest="LINECHECKSUM", action="store_true", help="Enable line check summing.")
    optGrpOptions.add_option("--no-checksum", dest="LINECHECKSUM", action="store_false", help="Disable line check summing.")
    optGrpOptions.add_option("--ignore-errors", dest="IGNOREERRORS", action="store_true", help="Continue after ERRORS (gcov, source, graph).")
    optGrpOptions.add_option("--no-recursion", dest="RECURSION", action="store_false", help="Exclude sub-directories from processing.")
    optGrpOptions.add_option("--no-markers", dest="EXCLUSIONMARKERS", action="store_false", help="Ignore exclusion markers in source code.")
    optGrpOptions.add_option("--derive-func-data", dest="GENFUNCDATA", action="store_true", help="Generate function data from line data.")
    optParser.add_option_group(optGrpOptions)

    try:

        (cmdOptions, cmdArgs) = optParser.parse_args()

        try:
            validate_options(cmdOptions, cmdArgs)

            if cmdOptions.CAPTURE:
                operation_capture(cmdOptions, cmdArgs)

            elif cmdOptions.MERGE:
                operation_merge(cmdOptions, cmdArgs)

            elif cmdOptions.PARSE:
                operation_parse(cmdOptions, cmdArgs)

            elif cmdOptions.REMOVE:
                operation_merge(cmdOptions, cmdArgs)

            elif cmdOptions.ZEROCOUNTERS:
                operation_zerocounters(cmdOptions, cmdArgs)
        except OptParseError as optError:
            print(str(optError))
            print("")

            optParser.print_help()

    except SystemExit:
        print("")

    return

if __name__ == "__main__":
    try:
        pycover_main()
    except:
        import traceback

        (exType, exValue, exTraceBack) = sys.exc_info()
        traceback.print_exception(exType, exValue, exTraceBack)
    pass

